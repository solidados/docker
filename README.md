# Docker

## Entry
> Docker – это платформа для разработуи, доставки и запуска контейнерных приложений.

Позволяет:
- создавать контейнеры
- автоматизировать их запуск и развёртынвание
- управлять их жизненным циклом

Docker инкапсулирует в образе:
- Операционную систему
- среду запуска
- все конфигурации и настройки
- приложения
- и т.д.

## Важиные Концепции Docker
1. `Docker Images` (образы)
> образ – это своего рода чертёж для контейнера.

Он содержит такие элементы как:
- рабочая среда (например конкретная версия Node)
- код приложения
- зависимости (dependencies)
- конфигурации
- переменные среды (.env)
- команды (которые нужно запустить, чтобы приложение работало)

Образы так же имеют собственную файловую систему, которая не зависима от остальной части. Как только Образ был создан, то он уже не может быть изменён. И если требуется внести изменения, то необходимо создать совершенно новый образ, чтобы включить эти изменения.

2. `Docker Containers` (контейнеры)
> контейнеры - это исполняемые экземпляры созданных образов

Docker контейнер производит (изолированный процесс):
- запуск экземпяра образа
- запуск приложения
 
## VM vs. Container
Каждая созданная виртуальная машина, запускает свою собственную полноценную Операционную систему с собственным ядром, которое работает поверх операционной сисиемы рабочего компьютера. 

Контейнеры этого не делают! Они используют ядро ОС рабочего компьютера, поэтому они более лёгкие и менее ресурсо-затратные. Это так же означает, что они обычно быстрее запускаются и используют меньше памяти.  
Контейнеры включают в себя облегчённую версию конкретной ОСи, но они всё ещё используют ябро хост-машины в качестве основы. Так что контейнеры гораздо легче и быстрее `Virtual Machines`

## Docker Image (образ)
Образы состоят из нескольких слоёв, где каждый слой инкрементно добавляет что-то своё к каждому образу.

|     | Слои образов            |               |
| --- | ----------------------- | ------------- |
| 4   | Конфигурации            |               |
| 3   | Зависимости             |               |
| 2   | Код приложения          |               |
| 1   | Родительский образ (ОС) | (Node, Linux) |

Порядок слоёв имеет значение.  
1. Обычно, образ начинается с сущности, которая называется **родительским образом**. По сути, это и есть первы и основной слой. Этот слой описывает лёгкую ОС и рабочую среду контейнера. Можно создать контейнер с родительским образом, в котором будет установлена определённая версия `Node` на дистрибутиве `Linux`, и этот слой сам по себе уже представляет предварительно созданный **докер-образ**.  
2. Все последующие слои могут быть чем угодно

### Содание первого образа и его слоёв
1. Выполненная [Команда `docker pull node`](./commands.md/#команда-pull) загрузит последнюю официальную версию `Node` в начальный основной (Родительский) слой образа.  
2. Чтобы превратить проект в **докер-образ** в его корневой директории необходимо создать `Dockerfile`. По сути, это набор инструкций, которые сообщают `Docker` как создать образ со всеми своими различными слоями.  
Каждая инстуркция будет находитьс на отдельной строке внутри этого файла. Каждая инструкция в `Dockerfile` представляет собой разный слой в конечном образе.  
- Первой инструкцией будет первый слой `Node`, который был скачен с `docker-hub` - `FROM node:22-alpine` 
> `22-alpine` вместо `latest` - это дистрибутив Linux, который известен своим минимальным размером и ориентацией на безопасность
- Далее добавляется инструкция `WORKDIR` с указанием пути рабочего католога
- Следующим слоем добавляется инструкция для копирования кода приложения, который находится в папаке  `/api`
  + точка `.` – это относительный путь до папки с кодом (либо, если указана была `WORKDIR`, то путь нужно указывать так: `. .` – это означает, что код необходимо скопировать в корень рабочей директории `app`)
  + внутри образа будет создана папка `app`, куда будут скопированы все файлы проекта
- Следующий слой – это установка всех зависимостей, необходимых для работы приложения `RUN npm install`
- Следующая инструкция сообщает Docker, какой порт должен быть открыт для запуска приложения: `EXPOSE 3000`
- Завершающим слоем должна быть команда для запуска самого приложения. для этого есть команда `npm run dev`, которая определена в файле `package.json`. Но это не совсем верно, поэтому используется команда `CMD` перечисляющая команды, которые должны выполняться при запуске контейнера. То есть, когда установка будет произведена, эта команда запустит скрипт внутри контейнера: `CMD ["npm", "run", "dev"]`

## Получение доступа к контейнеру снаружи

## Layers caching
### Процесс оптимизации процесса сборки образа
Каждая строка, записанная в `Dockefile` представляет собой новый слой.
```dockerfile
# загрузка образа Node и версия оптимизации образа
FROM node:22-alpine

# указание рабочей директории. Эта инфо добавляется как слой в финальный образ
WORKDIR /app

# копирование исходных файлов на образ
COPY . .

# установка зависимостей... и так далее. 
RUN npm install

# каждая строка здесь представляет добавление новго слоя к образу.
```
При внесении каких-либо изменений в исходный код, необходимо пересобрать новый образ, чтобы подхватить эти изменения.  
Если этого не сделать, то контейнеры будут создавать на основе старого образа со старым кодом.
```shell
$ docker build -t <новое имя образа> .
```

> На этот раз создание должно занимать меньше времени, так как каждый раз, кода `Docker` пытается создать образ и проходит через разные слои, он сохраняет этот образ на каждом слое в `cache`. Другими словами, после каждого слоя, `Docker` берёт актуальное состояние образа и сохраняет его в `cache`.

Однако при иизменении кода, DOcker берёт из кэша только то, что было до изменённого слоя, а всё, что после –запускает снова, как например – `npm install` 

Но этот процесс так же можно оптимизировать, поменяв слой копирования (COPY) и установки (INSTALL) местами. В случае 
изменения исходного кода, слой установки будет браться из `cache`.

Однако есть нюанс: когда Docker доходит до слоя INSTALL, то `package.json` ещё отсутствует, так как он находится на слое COPY. Поэтому необходимо добавить слой, который будет копировать только один файл и помещать его в рабочую директорию.

> Больше информации о кэшировании слоёв и оптимизации сборки [читать документацию](https://docs.docker.com/build/cache/)

## Управление образами и теги (Image management and Tags)
### Тегирование образов
Когда мы разбирали кэширование слоёв, то в Docker всегда оставалось несколько образов, которые имеют примерно один и тот же код. И если их нужно удалить, то можно воспользоваться командами для образов: 
- [вывод списка образов](./commands.md/#команда-images)
- [удаление образа](./commands.md/#команда-image-rm)

Полная очистка кэшей, образов и контейнеров Docker производится общей командой [`system prune`](./commands.md/#команда-system-prune) 

После этого, можно приступить к созданию образа с присуждённым тегом: например:
```shell
$ docker build -t server-app:v1.0
```
Чтобы запустить контейнер этого образа, необходимо вводить не только имя образа, но и его тег, вот так:
```shell
$ docker run -d --name test-1 -p 3001:3000 server-app:v1.0
```

Сейчас были примеры того, как перенести приложение в Docker container. Однако мы обычно ведём разработку локально, и соответственно, все библиотеки, плагины, и прочее – уже становлено и работает. То есть локально есть папака `node_modules`, котору вовсе не нужно переносить в контейнер, так как там будет произведена своя установка согласно описанной иснструкции в слое `RUN npm install`.  

Для этого, в каталоге проекта, нужно создать файл `.dockerignore`, который работает точно так же, как и `.gitignore` (к примеру)

## Докер тома (Docker Volumes)
Ранее был рассмотрен вариант изменения рабочего кода проекта, что предполагает:
- новую сборку образа
- создание нового контейнера
- запуск контейнера  

И так каждый раз при любых изменениях в коде.

Однако есть и другой подход – тома (Volumes)  
- Volumes - это функция Docker, которая позволяет указать папки на host-machine, которые могут быть доступны для работающих контейнеров, что позволяет сопоставить локальные папки на host machine с определёнными папками внутри контейнера.   
- Если что-то изменится в этих папках локально, оно так же изменится и в контейнере

По сути, тома позволяют сохранять данные вне области жизни контейнера, и позволяет разделять данные между контейнерами, и что ещё важнее – **сохранять нужные данные при удалении контейнера**

> Простым языком, Тома - это способ, при помощи которого можно вносить изменения в проект и просматривать эти изменения, не создавая новые образы каждый раз. (важно: сам образ при этом не изменяется)

По сути, **Тома** помогают во время разработки, чтобы можно было видеть вносимые изменения бес постоянных пересборок.

Но чтобы отправить рабочую версию проекта, придётся снова пересоздать образ при помощи `docker build` и на его освновании контейнер.

### Запуск контейнера с настроенными томами
```shell
$ docker run -d --name test-2 -p 3002:3000 --rm -v <абсолютный пусть на host-machine до отслеживаемого файла/или папки - Source (Host)>:<путь до папки приложения и файла/папки в ней - Destination (Container)> server-app:nodemon
```
- докер, создай контейнер
- по `--name` имени `test-2`
- у которго будет выход через порт `3002` в приложении на порту `3000`
- `--rm` при остановке мгновенно нужно будет удалить контейнер
- сделай это из образа по имени `server-app:nodemon`

то есть вариант отслеживания изменений в одном файле будет выглядеть так:
```shell
$ docker run -d --name test-2 -p 3002:3000 --rm -v /Users/username/projects/docker/api/db.mjs:/app/db.mjs server-app:nodemon
```

Стоит обратить внимание на изменения, внесённые в `Dockerfile` и `package.json`

Чтобы подписаться на изменения во всей папке проекта, можно остановить предварительно контейнер, и выполнить команду, которая укажет пути целиком до директорий, за изменениями в которых нужно следить. Однако, так как в контейнере появиятся папка `node_modules`, а локально её нет, то в команду нужно будет добавить ещё один параметр:
```shell
$ docker run -d --name test-2 -p 3002:3000 --rm -v /Users/username/projects/docker/api/:/app/ -v app/node_modules server-app:nodemon
```
Вместо связывания директории на локальной машине с директорией в Docker, - создаём анонимный модуль для node_modules: `-v app/node_modules`.  
Другими словами, - вместо создания связи, используются модулии контейнера.

### Итог проделанной работы с томамию
1. в `Dockerfile` добавили слой установки `RUN npm install nodemon`, чтобы динамически отслеживать изменения в коде и обновлять сервер
2. Используя `Docket Volume` соотнёс ликальные файлы `-v /Users/username/projects/docker/api/:` с файлами контейнера `:/app/`. При такой связи локальные изменения тригерят изменения в контейнере, что позволяет менять контейнер без его постоянных остановок, новых сборок образов и перезапусков
3. Создал анонимный модуль node_modules `-v app/node_modules`.

Всё это помогает локальной рзработке. Для финальной версии кода, необходимо будет остановить контейнер, пересобрать образ и запустить контейнер снова.  

## Docker Compose
Помогает оптимизировать работу с Docker.  
Ранее, каждый раз, когда запускаем образ, приходилось вводить длинную команду в терминале для указания:
- имени контейнера `--name test-2`
- сопоставления портов `-p 3002:3000`
- томов `-v <absolute path to folder on host>:<relative path to app folder>`
- дополнительной конфигурации использования модулей контейнера `-v app/node_modules`
- и так далее...

Зачастую бывает так, что есть несколько проектов, и нужно запустить все контейнеры одновременно. Например:
- api на Node.js
- база данных на mongoDB
- фронт на React  

и всё это нужно запускать одновременно, чтобы отдлельные приложения, или сервисы, могли общаться друг с другом.

> Docker Compose - это встроенный инструмент Docker, который позволяет создать единый файл Docker Compose, который содержит вс/ необходимую конфигурацию контейнеров наших проектов, и в нём можно определить сопоставление портов, тома, имена контейнеров, и так далее. И этот единый файл будет настраивать разные контейнера, которые необходимо запустить одновременно.

1. в корневой папке проекта (важно!) нужно создать файл `docker-compose.yaml`. Все отступы в `*.yaml` файле имеют значение
2. указывается версия docker-compose. Чтобы узнать доступную версию:  
```shell
$ docker compose version
```
3. далее указывается `services` - это объект со своими свойствами и зачениями, которые сообщают Docker как построиить образ для сервиса, а так же как запустить контейнер для него.
> В контексте Docker Compose `service` - это отдельное приложение, которое необходимо сконфигурировать, и для которого нужно создать образ и контейнер 

4. на данный момент есть только один сервис – `api`, поэтому добавляется одноимённая служба в файл `docker-compose` как свойтво объекта `services`. Название не обязательно должно быть таким, как у директории, – просто для большей ясности.
5. у службы `api` сначала настраиваю образ. Для этого нужно указать инструкцию `build:` чтобы показать, как будет строиться образ (Image). Значением указывается относительный путь к директории, где находится `Dockerfile` для этого проекта. Это нужно потому, чтобы `docker-compose` использовал `Dockerfile` который применяется для создания образа.
6. следующее свойство - имя контейнера `container_name` (сообщает Docker как назвать контейнер для этого образа). Если сопоставлений портов несколько, их можно указать один под другим.
7. следующее свойство – `volumes` - любые тома, которые будут созданы при запуске образа для создания контейнера. В этот раз уже не нужно указывать абсолютный путь до папки:
 - сначала сопоставляем директории локально и в контейнере `- ./api:/app`
 - далее инструкция для использования модулей контейнера `- /app/node_modules`
8. После того, как все инструкции созданы, можно запустить одной командой:
```shell
$ docker compose up
```
- будет создан образ
- на основаниии образа будет создан контейнер
- контейнер запустится и будет доступен через указанный порт (например 3001)
9. чтобы остановаить и удалить контейнер, достаточно простой команды:
```shell
$ docke compose down
```
Но при этом удаляется только контейнер, а образы и тома – остаются.  
Чтобы выполнить полную остановку и удаление всего, к этой команде добавляется:
```shell
$ docker compose down --rmi all
```
